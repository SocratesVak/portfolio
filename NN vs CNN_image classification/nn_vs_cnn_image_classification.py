# -*- coding: utf-8 -*-
"""NN vs CNN_image classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RcVYdtn9-EUYp07qM8muNcIP3U3VngVa

**Artificial Neural Network**
"""

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.datasets import mnist
import matplotlib.pyplot as plt

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Normalize the images.
train_images = (train_images / 255) - 0.5
test_images = (test_images / 255) - 0.5

# Flatten the images.
train_images_ANN = train_images.reshape((-1, 784))
test_images_ANN = test_images.reshape((-1, 784))

model = Sequential([Dense(256, activation='relu', input_shape=(784,)), Dense(128, activation='relu'), Dense(10, activation='softmax')])

# Compile the model.
model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

train_history= model.fit(train_images_ANN,to_categorical(train_labels),epochs=10,validation_split=0.1,batch_size=512)

# show_train_history function
def show_train_history(train_history,train,validation):
  plt.plot(train_history.history[train])
  plt.plot(train_history.history[validation])
  plt.title('Train History')
  plt.ylabel(train)
  plt.xlabel('Epoch')
  plt.legend(['train', 'validation'], loc = 'upper left')
  plt.show()

 # Call the function using these arguments
show_train_history(train_history,'accuracy','val_accuracy')
show_train_history(train_history,'loss','val_loss')

"""# Σχολιασμός Artificial Neural network

Οι δύο δείκτες μας δείχνουν μια ικανοποιητική απόδοση του νευρωνικού δικτύου. Συγκεκριμένα, ο δείκτης accuracy ανεβαίνει και στο training και στο validation set όσο περνάνε οι εποχές. Αντίστροφα, o δείκτης loss παρουσιάζει πτωτική τάση και στα δύο set, όσο περνάνε οι εποχές. Επομένως, δε συναντάμε overfitting ή underfitting προβλήματα.
"""

test_loss, test_acc = model.evaluate(test_images_ANN,  to_categorical(test_labels))
print("Accuracy of ANN in test set:", test_acc)

from sklearn.metrics import ConfusionMatrixDisplay
predictions = model.predict(x=test_images_ANN, batch_size=1000)
rounded_predictions = np.argmax(predictions, axis=1)
print(rounded_predictions)
print(test_labels)
ConfusionMatrixDisplay.from_predictions(test_labels,rounded_predictions, labels=[0,1,2,3,4,5,6,7,8,9])
plt.show()

"""# Σχολιασμός Artificial Neural network

Παρατηρούμε ότι το νεωρωνικό μας δίκτυο αποδίδει πολύ καλα, όπως συνηγορούν ο δείκτης accuracy(=0.975) στο test set, όσο και το confusion matrix. Το δίκτυο έχει την ικανότητα γενίκευσης χωρίς να εντοπίζονται φαινόμενα overfitting ή underfitting.

**Convolutional Neural Network**
"""

import tensorflow as tf
from tensorflow.keras import datasets, layers, models

train_images_CNN = np.expand_dims(train_images,-1)
test_images_CNN = np.expand_dims(test_images,-1)

model=models.Sequential()
model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])

train_history = model.fit(train_images_CNN, train_labels, epochs=10, validation_split=0.1, batch_size=512)

# Call the function using these arguments
show_train_history(train_history,'accuracy','val_accuracy')
show_train_history(train_history,'loss','val_loss')

"""# Σχολιασμός Convolutional Neural network

Και το συνελικτικό νευρωνικό αποδίδει πολύ καλά και στα δύο set, training και validation, όπως φανερώνουν οι άνωθι δείκτες, accuracy και loss. Και πάλι δεν αντιμετωπίζουμε προβλήματα overifitting ή underfitting.
"""

test_loss, test_acc = model.evaluate(test_images_CNN,  test_labels)
print("Accuracy of CNN in test set:", test_acc)

from sklearn.metrics import ConfusionMatrixDisplay
predictions = model.predict(x=test_images_CNN, batch_size=1024)
rounded_predictions = np.argmax(predictions, axis=1)
ConfusionMatrixDisplay.from_predictions(test_labels,rounded_predictions, labels=[0,1,2,3,4,5,6,7,8,9])
plt.show()

"""# Σχολιασμός Convolutional Neural network

Παρατηρούμε ότι το συνελικτικό νευρωνικό πηγαίνει ελαφρώς καλύτερα από το τεχνητό νευρωνικό δίκτυο στην επεξεργασία του test set (accuracy in ANN:0.975,
accuracy in CNN:0.987). Τα συνελικτικά δίκτυα έχουν στο εσωτερικό της διεργασιών τους τη δημιουργία πολλών feature maps, τα οποία αποκρυσταλλώνουν την πληροφορία των εικόνων σε κλιμακωτά επίπεδα. Πρώτα, συγκεντρώνουν αδρή πληροφορία για τις εικόνες, που αφορά ακμές και γωνίες. Τα επόμενα feature maps προχωρούν στη συγκέντρωση περισσότερης πληροφορίας. Με αυτόν τον τρόπο καταφέρνουν να αναλύσουν μεθοδικότερα και διεξοδικότερα τα εισαγόμενα, γεγονός που διατρανώνεται στην ακρίβεια της ταξινόμησης. Γενικώς, θεωρούνται πλέον κατάλληλα συγκριτικά με τα τεχνητά νευρωνικά δίκτυα στην ανάλυση εικόνων, όπως άλλωστε αποδείχτηκε και στην εν λόγω εργασία.

**Convolutional Neural Network with max pooling**
"""

# CNN with max pooling
model=models.Sequential()
model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(128, activation='relu'))
model.add(layers.Dense(10, activation='softmax'))

model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])

train_history = model.fit(train_images_CNN, train_labels, epochs=10, validation_split=0.1, batch_size=512)

# Call the function using these arguments
show_train_history(train_history,'accuracy','val_accuracy')
show_train_history(train_history,'loss','val_loss')

"""# Σχολιασμός Convolutional Neural network with max pooling

Συγκρίνοντας το συνελικτικό νευρωνικό χωρίς την προσθήκη pooling layer με το συνελικτικό, που διαθέτει εγκιβωτισμένα pooling layers, παρατηρούμε ότι στο δεύτερο η απόδοση βελτιώνεται ελαφρώς. Οι καμπύλες των accuracy και loss στο validation set είναι συγκριτικά πολύ πιο σταθερές στο διάβα των εποχών. Επίσης, ο χρόνος εκπαίδευσης του συνελικτικού με τα pooling layers μείωνεται σημαντικά. Γενικώς, η προσθήκη τους ανεβάζει την απόδοση του δικτύου. 
"""

test_loss, test_acc = model.evaluate(test_images_CNN, test_labels)
print("Accuracy of CNN(with max pooling) in test set:", test_acc)

predictions = model.predict(x=test_images_CNN, batch_size=1024)
rounded_predictions = np.argmax(predictions, axis=1)
ConfusionMatrixDisplay.from_predictions(test_labels,rounded_predictions, labels=[0,1,2,3,4,5,6,7,8,9])
plt.show()

"""# Σχολιασμός Convolutional Neural network with max pooling

Ως προς το δείκτη accuracy και το confusion matrix στο test set, η βελτίωση σε σύγκριση με το συνελικτικό δίκτυο χωρίς pooling layers είναι υπαρκτή μεν, ισχνή δε (accuracy of CNN with pooling layers: 0.9886, accuracy of CNN without pooling layers 0.9869). Επομένως, η υψηλότερη ταχύτητα εκπαίδευσης, η σταθερότητα των καμπυλών στους δείκτες accuracy και loss στο validation set και το υψηλότερο accuracy στο test set συνηγορούν υπέρ της προσθήκης pooling layers στο συνελικτικό δίκτυο.

---

# Γενικό σχόλιο αναφορικά με τα batches
Πειραματιζόμενος με το μέγεθος των batch sizes των υπό εκπαίδευση δικτύων, παρατήρησα, ότι όσο μικρότερο ήταν το batch size, τόσο πιο έντονα προβλήματα overfitting συνάντησα. Προσπαθώντας να ερμηνεύσω το φαινόμενο, εκτιμώ ότι αυτό συμβαίνει λόγω του γεγονότος ότι μετά από το πέρας της επεξεργασίας κάθε batch, το δίκτυο προβαίνει σε backpropagation, δηλαδή τον επανακαθορισμό των βαρών. Επομένως, όσο μικρότερο είναι το batch size, τόσο περισσότερες φορές γίνεται αυτός ο επανακαθορισμός, με αποτέλεσμα να προκαλείται μια υπερπροσαρμογή στα δεδομένα εκπαίδευσης με την επακόλουθη ανικανότητα του δικτύου να γενικεύσει.
"""